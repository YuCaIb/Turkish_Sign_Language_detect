This project is in development process so scripts are not ready and working properly. It aimed to finish the project's first phase by the end of the july/2024, purpose is creating a Turkish Sign Language Recognizer.
It aimed to be based on mediapipe's "Holositcs" LandMark Detection model.

# Why I do develop this project ?
It is predicted that Türkiye has 836 k people that are deaf and mute.  Those people are using Turkish Sign Language to communicate. Türkiye's population is 836k out of  80 million is deaf and mute and  is just %0.01 percent ~ 0.01045.
So, many people does not know Turkish Sign Language(TSL) and there's only little percent that obligated to learn this language.
For the people that does not have deaf, mute relatives it is hard to understand TSL. In daily life you may need any language in any time.
Basically you can open translate and use these languages, What I aim for the future, that you can open your mobile app and understand sign language.


# Aimed Audience:
* People that does not know Turkish Sign Language and people that having hard time while learning it.


# What is the data ?
* Data is coming from Mediapipe's holistics model that provides landmarks for Face, Pose(Posture) and for both hands (left hand and right hand).

# Future Developments

* Model can be converted in to tensorflow lite version and integrated in to mobile application.
* Always, can be added new words
